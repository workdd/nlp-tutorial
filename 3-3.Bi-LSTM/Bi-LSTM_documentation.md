# Bi-LSTM (Bidirectional Long Short-Term Memory)

## 개요
Bi-LSTM은 LSTM의 확장 버전으로, 시퀀스를 양방향(정방향과 역방향)으로 처리하여 더 풍부한 문맥 정보를 포착하는 모델입니다. 이를 통해 각 시점에서 과거와 미래의 정보를 모두 활용할 수 있습니다.

## 주요 특징
- 정방향(forward)과 역방향(backward) LSTM을 결합
- 각 단어/토큰에 대해 양방향의 문맥 정보 활용
- 시퀀스의 전체 문맥을 더 효과적으로 포착
- 긴 문장에서 다음 단어 예측 성능 향상

## 구현 내용
이 노트북에서는 PyTorch를 사용하여 Bi-LSTM 모델을 구현하고 있습니다:

1. 텍스트 데이터셋 준비 및 전처리
2. 단어 임베딩 초기화
3. Bi-LSTM 모델 구현:
   - 임베딩 레이어
   - 양방향 LSTM 레이어
   - 은닉 상태 결합
   - 출력 레이어
4. 모델 학습 및 긴 문장에서 다음 단어 예측 성능 평가

## Bi-LSTM의 작동 방식
1. 정방향 LSTM: 시퀀스를 처음부터 끝까지 처리
2. 역방향 LSTM: 시퀀스를 끝에서 처음까지 처리
3. 두 방향의 은닉 상태 결합(concatenate 또는 sum)
4. 결합된 표현을 사용하여 예측 수행

## Bi-LSTM의 장점
- 각 시점에서 과거와 미래의 문맥 정보 모두 활용
- 시퀀스 라벨링 작업에서 우수한 성능
- 문맥 이해 능력 향상

## 응용 분야
- 개체명 인식(Named Entity Recognition)
- 품사 태깅(POS Tagging)
- 감성 분석
- 기계 번역
- 질의응답 시스템
- 문장 완성

## 참고 자료
- Bi-LSTM은 현대 NLP와 LLM 시스템에서 중요한 구성 요소로, 특히 시퀀스 라벨링 작업에서 널리 사용됩니다.
- 트랜스포머 모델이 등장하기 전까지 양방향 문맥 모델링의 표준으로 사용되었습니다.
